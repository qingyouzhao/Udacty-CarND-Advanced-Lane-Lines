{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "- Apply a distortion correction to raw images.\n",
    "- Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "- Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "- Detect lane pixels and fit to find the lane boundary.\n",
    "- Determine the curvature of the lane and vehicle position with respect to center.\n",
    "- Warp the detected lane boundaries back onto the original image.\n",
    "- Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "# todo(qingyouz): prototype here, then move to a calibration file\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.15777930e+03 0.00000000e+00 6.67111054e+02]\n [0.00000000e+00 1.15282291e+03 3.86128937e+02]\n [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n[[982.00366211   0.         679.60492147]\n [  0.         968.17901611 388.5261257 ]\n [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# prepare object points\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "# Make a list of calibration images\n",
    "camera_cal = 'camera_cal'\n",
    "camera_cal_images = os.listdir(camera_cal)\n",
    "\n",
    "# Hard code the points based on https://docs.opencv.org/3.4/dc/dbb/tutorial_py_calibration.html \n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "def get_objp(nx, ny):\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "    return objp\n",
    "\n",
    "check_objp = get_objp(nx, ny)\n",
    "print(check_objp.shape)\n",
    "\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\\\n",
    "    \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "    undist = np.copy(img)  # Delete this line\n",
    "    undist = cv2.undistort(img, mtx, dist, None, None)\n",
    "    return undist\n",
    "\n",
    "objpoints= []\n",
    "imgpoints= []\n",
    "\n",
    "for fname in camera_cal_images:\n",
    "    f = os.path.join(camera_cal, fname)\n",
    "    print(f)\n",
    "    img = cv2.imread(os.path.join(camera_cal, fname))\n",
    "    print(img.shape)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    # If found, draw corners and append them to objpoints and imgpoints\n",
    "    if ret == True:\n",
    "        # Draw and display the corners\n",
    "        # print(corners)\n",
    "        objpoints.append(check_objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "        plt.imshow(img)\n",
    "\n",
    "# Now we gathered all points calibrate\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.15777930e+03 0.00000000e+00 6.67111054e+02]\n [0.00000000e+00 1.15282291e+03 3.86128937e+02]\n [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n[[982.00366211   0.         679.60492147]\n [  0.         968.17901611 388.5261257 ]\n [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(os.path.join(camera_cal, 'calibration1.jpg'))\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "print(mtx)\n",
    "print(newcameramtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undistort and store\n",
    "# todo(qingyouz): \n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite(os.path.join('output_images', 'calibresult.png'), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply distortion to raw images\n",
    "raw_imgs = os.listdir('test_images/')\n",
    "undistort_imgs = []\n",
    "for i in raw_imgs:\n",
    "    img = cv2.imread(os.path.join('test_images/', i))\n",
    "    undistort = cv2.undistort(img, mtx, dist, None, None)\n",
    "    undistorted_file = os.path.join('output_images', 'ud'+i)\n",
    "    cv2.imwrite(undistorted_file, undistort)\n",
    "    undistort_imgs.append(undistorted_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use color transforms, gradients, etc., to create a thresholded binary image\n",
    "# Edit this function to create your own pipeline.\n",
    "def thresholded_pipeline(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    return color_binary\n",
    "    \n",
    "color_binaries = []\n",
    "for filename in undistort_imgs:\n",
    "    img = cv2.imread(filename)\n",
    "    color_binary = thresholded_pipeline(img)\n",
    "    ext = os.path.splitext(filename)[-1]\n",
    "    f = os.path.join(*os.path.splitext(filename)[:-1]) + \"_color_binaries\"+ext\n",
    "    color_binaries.append(f)\n",
    "    cv2.imwrite(f, color_binary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
